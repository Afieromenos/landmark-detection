{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install keras==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from tensorflow import keras\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os \n",
    "import random \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=20000\n",
    "df=df.loc[:samples,:]\n",
    "num_classes = len(df[\"landmark_id\"].unique())\n",
    "num_data= len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(df[\"landmark_id\"].value_counts())\n",
    "\n",
    "data.reset_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['index','landmark_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['landmark_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['landmark_id'],100,range=(0,58),label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['landmark_id'].between(0,5).sum()\n",
    "data['landmark_id'].between(5,10).sum()\n",
    "data['landmark_id'].between(10,15).sum()\n",
    "data['landmark_id'].between(15,20).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"landmark_id\"], bins=df[\"landmark_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(df[\"landmark_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['id'].str.startswith('000')]\n",
    "df = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    " return labelencoder.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_label(label):\n",
    " return labelencoder.inverse_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "def get_img_from_num(num, df):\n",
    "   if 0 <= num < len(df): # Check if the index is within the DataFrame length\n",
    "     fname, label = df.iloc[num, :]\n",
    "     print(fname)\n",
    "     f1, f2, f3 = fname[:3] # Extracting first three characters\n",
    "     path = os.path.join(\"./images\", f\"images_{f1}{f2}{f3}\", f1, f2, f3, f\"{fname}\")\n",
    "    try:\n",
    "      img = cv2.imread(path)\n",
    "      if img is not None:\n",
    "        print(img)\n",
    "        return img, label\n",
    "      else:\n",
    "        print(f\"Error: Unable to read image at path: {path}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    return None, None\n",
    "   else:\n",
    "    print(\"Error: Index out of bounds or DataFrame length is insufficient.\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i in range(1, 5):\n",
    "    rimg = random.choices(os.listdir(\"./images/images_000/0/0\"), k=3)\n",
    "    print(rimg)\n",
    "    \n",
    "    folder = \"./images/images_000/0/0\" + \"/\" + rimg[2]\n",
    "    random_img = random.choice(os.listdir(folder))\n",
    "    \n",
    "    iimg = np.array(Image.open(folder + \"/\" + random_img))\n",
    "    fig.add_subplot(1, 4, i)\n",
    "    plt.imshow(iimg)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import *\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "learning_rate = 0.001\n",
    "decay_speed = 1e-6\n",
    "momentum = 0.09\n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "source_model = VGG19(weights=None)\n",
    "drop_layer = Dropout(0.5)\n",
    "drop_layer2 = Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for layer in source_model.layers[:-1]:\n",
    "   if layer == source_model.layers[-25]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(layer)\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(lr=learning_rate),\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_reshape(img, size):\n",
    "    return cv2.resize(img, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataframe, start, batch_size):\n",
    "    image_array = []\n",
    "    label_array = []\n",
    "    \n",
    "    end_image = start + batch_size\n",
    "    if(end_image) > len(dataframe):\n",
    "        rend_image = len(dataframe)\n",
    "\n",
    "    for idx in range(start, end_image):\n",
    "        n = idx\n",
    "        img, label = get_img_from_num(n, dataframe)\n",
    "        img = image_reshape(img, (224, 224)) / 255.0\n",
    "        image_array.append(img)\n",
    "        label_array.append(label)\n",
    "    label_array = encode_label(label_array)\n",
    "\n",
    "    return np.array(image_array), np.array(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epoch_shuffle = True\n",
    "weight_classes = True\n",
    "epochs = 1\n",
    "#Splitting the data with 80% of length\n",
    "train, val = np.split(df.sample(frac=1),[int(0.8*len(df))])\n",
    "print(len(train))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for e in range(epochs):\n",
    "    print(\"Epoch : \" + str(e+1) + \"/\" + str(epochs))\n",
    "    if epoch_shuffle:\n",
    "        train = train.sample(frac = 1)\n",
    "    for it in range(int(np.ceil(len(train)/batch_size))):\n",
    "        X_train, y_train = get_batch(train, it*batch_size, batch_size)\n",
    "        model.train_on_batch(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "batch_size = 16\n",
    "errors = 0\n",
    "good_preds = []\n",
    "bad_preds = []\n",
    "for it in range(int(np.ceil(len(val)/batch_size))):\n",
    "    X_val, y_val = get_batch(val, it*batch_size, batch_size)\n",
    "\n",
    "\n",
    "    print(\"Validation Image paths:\", X_val)\n",
    "\n",
    "    result = model.predict(X_val)\n",
    "    cla = np.argmax(result, axis=1)\n",
    "    for idx, res in enumerate(result):\n",
    "        if cla[idx] != y_val[idx]:\n",
    "            errors = errors + 1\n",
    "            bad_preds.append([batch_size*it + idx, cla[idx], res[cla[idx]]])\n",
    "        else:\n",
    "            good_preds.append([batch_size*it + idx, cla[idx], res[cla[idx]]])\n",
    "model.save(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_preds = np.array(good_preds)\n",
    "good_preds = np.array(sorted(good_preds, key = lambda x: x[2], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "for i in range(1, 6):\n",
    "    if i < len(good_preds):\n",
    "        n = int(good_preds[i][0])\n",
    "        img, lbl = get_image_from_number(n, val)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        fig.add_subplot(1, 5, i)\n",
    "        plt.imshow(img)\n",
    "        lbl2 = np.array(int(good_preds[i][1])).reshape(1, 1)\n",
    "        sample_cnt = list(df.landmark_id).count(lbl)\n",
    "        plt.title(\"Label: \" + str(lbl) + \"\\nClassified as: \" + str(decode_label(lbl\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
